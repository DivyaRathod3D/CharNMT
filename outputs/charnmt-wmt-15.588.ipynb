{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone --single-branch --branch master https://github.com/DivyaRathod3D/CharNMT.git","metadata":{"execution":{"iopub.status.busy":"2023-01-02T04:53:32.984984Z","iopub.execute_input":"2023-01-02T04:53:32.986175Z","iopub.status.idle":"2023-01-02T04:54:08.789429Z","shell.execute_reply.started":"2023-01-02T04:53:32.986107Z","shell.execute_reply":"2023-01-02T04:54:08.788296Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'CharNMT'...\nremote: Enumerating objects: 233, done.\u001b[K\nremote: Counting objects: 100% (73/73), done.\u001b[K\nremote: Compressing objects: 100% (48/48), done.\u001b[K\nremote: Total 233 (delta 28), reused 70 (delta 25), pack-reused 160\u001b[K\nReceiving objects: 100% (233/233), 609.34 MiB | 38.73 MiB/s, done.\nResolving deltas: 100% (109/109), done.\nUpdating files: 100% (77/77), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"cd CharNMT","metadata":{"execution":{"iopub.status.busy":"2023-01-03T11:57:40.049020Z","iopub.execute_input":"2023-01-03T11:57:40.049359Z","iopub.status.idle":"2023-01-03T11:57:40.087673Z","shell.execute_reply.started":"2023-01-03T11:57:40.049329Z","shell.execute_reply":"2023-01-03T11:57:40.086600Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/working/CharNMT\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nimport logging\nlogging.basicConfig(\n        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n        datefmt=\"%m/%d/%Y %H:%M:%S\",\n        level=logging.INFO,\n)\n\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2023-01-03T11:57:40.089640Z","iopub.execute_input":"2023-01-03T11:57:40.090278Z","iopub.status.idle":"2023-01-03T11:57:40.156459Z","shell.execute_reply.started":"2023-01-03T11:57:40.090224Z","shell.execute_reply":"2023-01-03T11:57:40.155600Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class CharDataset(Dataset):\n    '''\n    Dataset is a iterable that returns input and target sentence. It adds <sos> at the begining, and <eos> at the end, \n    and filling in <pad> if sentence length is less than pre-defined value.\n    '''\n    \n    def __init__(self, x, y, sequence_len, encoder=None):\n        # data in the type of pairs of sentence\n        data = ''.join(x+y)\n        # from collections import Counter\n        # vocab_size = 250\n\n        # ct = Counter(data)\n        # include = sorted(ct, key=ct.get, reverse=True)\n        # if len(include)>vocab_size: include = include[:vocab_size]\n        # rule = ''.join(include)\n        chars = ['<pad>'] +['<sos>'] + ['<eos>'] + sorted(list(set(data)))\n        data_size, vocab_size = len(data), len(chars)\n\n        print('data has %d characters, %d unique chars, %d sentences.' % (data_size, len(chars), len(x)))\n        print('sentence length nine_nine_percentile: %d' % (sequence_len))\n        \n        self.x, self.y = x, y\n        self.ch2i = {ch:i for i,ch in enumerate(chars)}\n        self.i2ch = {i:ch for i,ch in enumerate(chars)}\n        self.vocab_size = vocab_size\n        self.sequence_len = sequence_len\n        self.encoder=encoder\n    \n    def __len__(self):\n        return len(self.x) # len x = y\n    \n    def __getitem__(self, idx):\n        \n        indx = self.padding([self.ch2i[ch] for ch in self.x[idx]] + [self.ch2i['<eos>']])\n        indy = [self.ch2i['<sos>']] + self.padding([self.ch2i[ch] for ch in self.y[idx]] + [self.ch2i['<eos>']])\n\n        x = torch.tensor(indx, dtype=torch.long)\n        y = torch.tensor(indy, dtype=torch.long)\n\n        return x,y\n                                                                                                                               \n    def padding(self, string):\n        if len(string)<self.sequence_len:\n            string =  string + [0]*(self.sequence_len - len(string))\n        else:\n            string = string[:self.sequence_len -1] + [self.ch2i['<eos>']]\n                   \n        return string","metadata":{"execution":{"iopub.status.busy":"2023-01-03T11:57:40.157893Z","iopub.execute_input":"2023-01-03T11:57:40.158252Z","iopub.status.idle":"2023-01-03T11:57:40.222465Z","shell.execute_reply.started":"2023-01-03T11:57:40.158219Z","shell.execute_reply":"2023-01-03T11:57:40.221431Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"sequence_len = 128\nmin_len = 0","metadata":{"execution":{"iopub.status.busy":"2023-01-03T11:57:40.225294Z","iopub.execute_input":"2023-01-03T11:57:40.225825Z","iopub.status.idle":"2023-01-03T11:57:40.280198Z","shell.execute_reply.started":"2023-01-03T11:57:40.225782Z","shell.execute_reply":"2023-01-03T11:57:40.279272Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# process and save data\nfrom utils.pre_processing import *\nfrom utils.utils import *\nen, hi = list(), list()\n# paths = [\"data/pib/\",\"data/hinden/\",\"data/indic/\"]\npaths = [\"data/wmt14/\"]\nfor path in paths:\n    x = open(path + \"Eng.txt\", encoding='utf-8').read().split(\"\\n\")\n    y = open(path + \"Hin.txt\", encoding='utf-8').read().split(\"\\n\")\n    x,y = pre_processing(x, y, min_length=min_len, max_length=sequence_len) # remove sentence less than 4 characters\n    en += x\n    hi += y\n    \npath = \"data/cleaned/\"\npickle(path + \"en\", en)\npickle(path + \"hi\", hi)\n# nine_nine_percentile = int(np.percentile([len(sen) for sen in vi],99))","metadata":{"execution":{"iopub.status.busy":"2023-01-03T11:57:40.281776Z","iopub.execute_input":"2023-01-03T11:57:40.282174Z","iopub.status.idle":"2023-01-03T11:57:48.054944Z","shell.execute_reply.started":"2023-01-03T11:57:40.282141Z","shell.execute_reply":"2023-01-03T11:57:48.053902Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"342265\nSome last sentences\nof the garden | बगीचे का\nin the centre of the garden | बगीचे के बीच में\non the elevated area situated in the centre of the garden | उद्यान के केन्द्र में स्थित ऊंचे स्थान पर\nin the pond which is on the elevated area situated in the centre of the garden | उस तालाब में जो उद्यान के केन्द्र में स्थित ऊंचाई पर स्थित है\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# Load saved data\nfrom utils.utils import *\nfrom utils.pre_processing import *\n\npath = \"data/cleaned/\"\nen = pickle(path+\"en\")\nhi = pickle(path+\"hi\")\nen,hi = pre_processing(en, hi, min_length=min_len, max_length=sequence_len) # clip sentences\nfor i in range(-1,-5,-1):\n    print(en[i],'|',hi[i])","metadata":{"execution":{"iopub.status.busy":"2023-01-03T11:57:48.056617Z","iopub.execute_input":"2023-01-03T11:57:48.057310Z","iopub.status.idle":"2023-01-03T11:57:52.038120Z","shell.execute_reply.started":"2023-01-03T11:57:48.057272Z","shell.execute_reply":"2023-01-03T11:57:52.037184Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"293652\nSome last sentences\nof the garden | बगीचे का\nin the centre of the garden | बगीचे के बीच में\non the elevated area situated in the centre of the garden | उद्यान के केन्द्र में स्थित ऊंचे स्थान पर\nin the pond which is on the elevated area situated in the centre of the garden | उस तालाब में जो उद्यान के केन्द्र में स्थित ऊंचाई पर स्थित है\nof the garden | बगीचे का\nin the centre of the garden | बगीचे के बीच में\non the elevated area situated in the centre of the garden | उद्यान के केन्द्र में स्थित ऊंचे स्थान पर\nin the pond which is on the elevated area situated in the centre of the garden | उस तालाब में जो उद्यान के केन्द्र में स्थित ऊंचाई पर स्थित है\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = CharDataset(hi, en, sequence_len=sequence_len)\n\nprint('sample tensors ', next(iter(dataset)))\nprint(\"vocab: \", dataset.ch2i)","metadata":{"execution":{"iopub.status.busy":"2023-01-03T11:57:52.039613Z","iopub.execute_input":"2023-01-03T11:57:52.040009Z","iopub.status.idle":"2023-01-03T11:57:52.759440Z","shell.execute_reply.started":"2023-01-03T11:57:52.039973Z","shell.execute_reply":"2023-01-03T11:57:52.757192Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"data has 20894274 characters, 162 unique chars, 293652 sentences.\nsentence length nine_nine_percentile: 128\nsample tensors  (tensor([121, 117, 127, 113, 129,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0]), tensor([ 1, 37, 53, 46, 63, 46, 46, 47, 54,  2,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0]))\nvocab:  {'<pad>': 0, '<sos>': 1, '<eos>': 2, ' ': 3, '!': 4, \"'\": 5, ',': 6, '.': 7, '0': 8, '1': 9, '2': 10, '3': 11, '4': 12, '5': 13, '6': 14, '7': 15, '8': 16, '9': 17, '?': 18, 'A': 19, 'B': 20, 'C': 21, 'D': 22, 'E': 23, 'F': 24, 'G': 25, 'H': 26, 'I': 27, 'J': 28, 'K': 29, 'L': 30, 'M': 31, 'N': 32, 'O': 33, 'P': 34, 'Q': 35, 'R': 36, 'S': 37, 'T': 38, 'U': 39, 'V': 40, 'W': 41, 'X': 42, 'Y': 43, 'Z': 44, '_': 45, 'a': 46, 'b': 47, 'c': 48, 'd': 49, 'e': 50, 'f': 51, 'g': 52, 'h': 53, 'i': 54, 'j': 55, 'k': 56, 'l': 57, 'm': 58, 'n': 59, 'o': 60, 'p': 61, 'q': 62, 'r': 63, 's': 64, 't': 65, 'u': 66, 'v': 67, 'w': 68, 'x': 69, 'y': 70, 'z': 71, 'ँ': 72, 'ं': 73, 'ः': 74, 'अ': 75, 'आ': 76, 'इ': 77, 'ई': 78, 'उ': 79, 'ऊ': 80, 'ऋ': 81, 'ऌ': 82, 'ऍ': 83, 'ऎ': 84, 'ए': 85, 'ऐ': 86, 'ऑ': 87, 'ऒ': 88, 'ओ': 89, 'औ': 90, 'क': 91, 'ख': 92, 'ग': 93, 'घ': 94, 'ङ': 95, 'च': 96, 'छ': 97, 'ज': 98, 'झ': 99, 'ञ': 100, 'ट': 101, 'ठ': 102, 'ड': 103, 'ढ': 104, 'ण': 105, 'त': 106, 'थ': 107, 'द': 108, 'ध': 109, 'न': 110, 'प': 111, 'फ': 112, 'ब': 113, 'भ': 114, 'म': 115, 'य': 116, 'र': 117, 'ल': 118, 'ळ': 119, 'व': 120, 'श': 121, 'ष': 122, 'स': 123, 'ह': 124, '़': 125, 'ऽ': 126, 'ा': 127, 'ि': 128, 'ी': 129, 'ु': 130, 'ू': 131, 'ृ': 132, 'ॄ': 133, 'ॅ': 134, 'ॆ': 135, 'े': 136, 'ै': 137, 'ॉ': 138, 'ॊ': 139, 'ो': 140, 'ौ': 141, '्': 142, 'ॐ': 143, '॑': 144, '॓': 145, '॔': 146, 'ॠ': 147, 'ॡ': 148, '।': 149, '॥': 150, '०': 151, '१': 152, '२': 153, '३': 154, '४': 155, '५': 156, '६': 157, '७': 158, '८': 159, '९': 160, '॰': 161}\n","output_type":"stream"}]},{"cell_type":"code","source":"from model.encode_decode_transformer import Transformer, TransformerConfig\nfrom utils.trainer import Trainer, TrainerConfig\ntconfig = TrainerConfig(max_epochs=1, batch_size=16, learning_rate=6e-4, grad_norm_clip=1.0, device='cuda',\n                       lr_decay=True, warmup_tokens=5000, ckpt_n_print_iter=4000, ckpt_path='checkpoint/transformer_hi_en_char_wmt')\n\nmconfig = TransformerConfig(vocab_size=dataset.vocab_size, sequence_len=dataset.sequence_len, embed_dim=256,\n                           n_block=8, n_head=8, device=tconfig.device)","metadata":{"execution":{"iopub.status.busy":"2023-01-03T11:57:52.762008Z","iopub.execute_input":"2023-01-03T11:57:52.762717Z","iopub.status.idle":"2023-01-03T11:57:52.902177Z","shell.execute_reply.started":"2023-01-03T11:57:52.762676Z","shell.execute_reply":"2023-01-03T11:57:52.901220Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = Transformer(mconfig)","metadata":{"execution":{"iopub.status.busy":"2023-01-03T11:57:52.903883Z","iopub.execute_input":"2023-01-03T11:57:52.904479Z","iopub.status.idle":"2023-01-03T11:57:53.200417Z","shell.execute_reply.started":"2023-01-03T11:57:52.904445Z","shell.execute_reply":"2023-01-03T11:57:53.199426Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"sentences = [\"मैं उससे मिलना चाहूँगा।\",\n           \"यह वही चीज़ है जिसकी मुझे ज़रूरत है।\",\n           \"मेरी चिंता मत करो।\",\n           \"उसने मुझे दो किताबें उधार दीं।\",\n           \"मैं इस योजना से सहमत हूँ।\"\n            ]\ntrainer = Trainer(model, dataset, tconfig, test_dataset=sentences, collate=None)","metadata":{"execution":{"iopub.status.busy":"2023-01-03T11:57:53.203980Z","iopub.execute_input":"2023-01-03T11:57:53.204375Z","iopub.status.idle":"2023-01-03T11:57:55.812811Z","shell.execute_reply.started":"2023-01-03T11:57:53.204337Z","shell.execute_reply":"2023-01-03T11:57:55.811797Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# # load pre-trained weights\nfrom utils.utils import pickle\nmodel.load_state_dict(pickle(tconfig.ckpt_path)) # load\n","metadata":{"execution":{"iopub.status.busy":"2023-01-03T11:57:55.814329Z","iopub.execute_input":"2023-01-03T11:57:55.814672Z","iopub.status.idle":"2023-01-03T11:58:01.514910Z","shell.execute_reply.started":"2023-01-03T11:57:55.814638Z","shell.execute_reply":"2023-01-03T11:58:01.513987Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-01-03T11:58:01.516443Z","iopub.execute_input":"2023-01-03T11:58:01.516813Z","iopub.status.idle":"2023-01-03T12:26:37.771029Z","shell.execute_reply.started":"2023-01-03T11:58:01.516778Z","shell.execute_reply":"2023-01-03T12:26:37.770022Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"epoch: 1 | train loss: 900.01603  | lr: 1.920000e-06:   0%|          | 0/18353 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"['And I would like to meet him.', \"It's the same thing that I need.\", \"Don't worry my concern.\", 'He borrowed me two books.', 'I agree with this scheme.']\n","output_type":"stream"},{"name":"stderr","text":"epoch: 1 | train loss: 0.35804  | lr: 5.402125e-04:  22%|██▏       | 4000/18353 [06:16<21:01, 11.37it/s]  ","output_type":"stream"},{"name":"stdout","text":"['I would like to meet him.', \"It's the same thing that I need it.\", \"Don't worry about me.\", 'He borrowed me two books.', 'I agree with this scheme.']\n","output_type":"stream"},{"name":"stderr","text":"epoch: 1 | train loss: 0.35084  | lr: 3.689517e-04:  44%|████▎     | 8000/18353 [12:31<15:13, 11.33it/s]   ","output_type":"stream"},{"name":"stdout","text":"[\"I'd like to meet it.\", \"It's the same thing that I need.\", \"Don't worry me.\", 'He borrowed me two books.', 'I agree with this plan.']\n","output_type":"stream"},{"name":"stderr","text":"epoch: 1 | train loss: 0.32126  | lr: 1.655665e-04:  65%|██████▌   | 11999/18353 [18:46<09:19, 11.37it/s] ","output_type":"stream"},{"name":"stdout","text":"['And I would like to meet him.', \"It's the same thing that I need.\", \"Don't worry my concern.\", 'He borrowed me two books.', 'I agree with this scheme.']\n","output_type":"stream"},{"name":"stderr","text":"epoch: 1 | train loss: 0.33557  | lr: 6.000000e-05:  87%|████████▋ | 16003/18353 [25:04<20:40,  1.89it/s]  ","output_type":"stream"},{"name":"stdout","text":"['I would like to meet him.', \"It's the same thing that I need.\", \"Don't worry me.\", 'He borrowed me two books.', 'I agree with this scheme.']\n","output_type":"stream"},{"name":"stderr","text":"epoch: 1 | train loss: 0.37875  | lr: 6.000000e-05: 100%|██████████| 18353/18353 [28:36<00:00, 10.69it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"samples = [\"इसी बीच एक बाइक पर तीन लोग आते दिखाई दिए।\",\n           \"तुम जवाब क्यों नहीं दे रहे हो?\",\n           \"ये किताबें मेरीं हैं।\",\n           \"आप की मदद के लिए धन्यवाद.\",\n           \"वह एक राजा से बहुत ज़्यादा था।\",\n           \"मैंने आज एक अद्भुत सपना देखा\"\n          ]\nresult = model.generate_output(samples, dataset, top_k=5, print_process=True)\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2023-01-03T12:26:37.772375Z","iopub.execute_input":"2023-01-03T12:26:37.773301Z","iopub.status.idle":"2023-01-03T12:26:44.006038Z","shell.execute_reply.started":"2023-01-03T12:26:37.773265Z","shell.execute_reply":"2023-01-03T12:26:44.005089Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"100%|██████████| 6/6 [00:06<00:00,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"['In the meantime, three people appeared on a bike.', 'Why are you not answering?', 'These books are me.', 'Thank you for your help.', 'He was much more than a king.', 'I saw a wonderful dream today']\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# benchmarking using bleu score\npath = \"/kaggle/input/newstest/\"\nen = open(path+\"test.en.txt\", encoding='utf-8').read().split(\"\\n\")\nhi = open(path+\"test.hi.txt\", encoding='utf-8').read().split(\"\\n\")\nen, hi = pre_processing(en, hi, min_length=min_len, max_length=sequence_len) # remove sentence less than 4 characters\n\nresult = model.generate_output(hi, dataset, top_k=5, print_process=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-03T12:26:44.008929Z","iopub.execute_input":"2023-01-03T12:26:44.009232Z","iopub.status.idle":"2023-01-03T12:54:04.903557Z","shell.execute_reply.started":"2023-01-03T12:26:44.009205Z","shell.execute_reply":"2023-01-03T12:54:04.902293Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"2507\nSome last sentences\n32 chartered planes have been booked to ferry the guests to and fro. | मेहमानों को लानेले जाने के लिए 32 चार्टर्ड विमानों की व्यवस्था की गई है।\n250 VIPs have been invited to this royal party. | इस शाही पार्टी के लिए 250 वीवीआईपी लोगों को भी आमंत्रित किया गया है।\nIt is noteworthy that both Nita and Isha are professional, classical dancers. | गौरतलब है कि नीता और ईशा दोनों ही प्रोफेशनल क्लासिकल डांसर है।\nIt is being said that Nita Ambani and her daughter Isha may also perform in this. | बताया जा रहा है कि नीता अंबानी और उनकी बेटी ईशा भी इसमें अपनी प्रस्तुती दे सकती है।\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1602/1602 [27:20<00:00,  1.02s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"from utils.utils import *\nscore, references, candidates = bleu_score(en, result)\nprint(score)","metadata":{"execution":{"iopub.status.busy":"2023-01-03T12:54:04.906012Z","iopub.execute_input":"2023-01-03T12:54:04.906687Z","iopub.status.idle":"2023-01-03T12:54:06.011443Z","shell.execute_reply.started":"2023-01-03T12:54:04.906648Z","shell.execute_reply":"2023-01-03T12:54:06.010383Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"15.588739145252545\n","output_type":"stream"}]}]}